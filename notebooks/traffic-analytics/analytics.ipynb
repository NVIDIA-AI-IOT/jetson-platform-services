{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "\n",
    "SPDX-License-Identifier: MIT\n",
    "\n",
    "# Traffic Analytics using Multi Class Support in Jetson Platform Services\n",
    "\n",
    "\n",
    "## Obtain spatio-temporal insights using APIs \n",
    "\n",
    "<b>Learning Objective:</b>\n",
    "- Use APIs to interact with the Analytics Services on Jetson Orin\n",
    "- Create line-crossing configuration and alerts using VST WebUI\n",
    "- Generate spatial insights like flow of vehicle movement and heatmaps\n",
    "\n",
    "<b>This lab is divided into 4 parts: </b>\n",
    "1. <b>Configure Tripwire (line-crossing) using VST WebUI</b><br>\n",
    "In the first section, users will experience the VST (Video Storage Toolkit) WebUI to create and configure Tripwire analytics. Not part of the lab, but users can use this WebUI to create virtual boundaries or region of interest (ROI)\n",
    "2. <b>Vehicle Movement Analytics</b><br>\n",
    "In this section, users will use the VST (/vst) and Analytics (/emdx) APIs to retrieve time series insights from the Analytics service. They will use this time series data to better understand the flow of vehicle movement. \n",
    "3. <b>Heatmap Analytics</b><br>\n",
    "In this section, user will use the behavior APIs from Analytics service to generate Heatmaps. Heatmaps provide a visualization to understand flow of traffic over time. This is generated by accumulating individual trajectories of movement and mapping it spatially over the region\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Traffic Movement Analytics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highway use case\n",
    "The specific example we will use in this lab includes understanding a 2-lane road scene along with a sidewalk. Each lane has vehicles moving in a specific direction.The concepts in this lab can be used with any streams and any movement of vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Concepts\n",
    "Each passage of interest will be marked using the concept of Tripwire. The actual path a vehicle takes is represented by a Trajectory. The system is capable of identifying the crossing of vehicles across Tripwire and provide a historical count of crossings via an API.\n",
    "\n",
    "#### Sensor and Streams\n",
    "The camera used to capture the video of the scene is called as a Sensor. The live feed from the camera is known as a Stream. These are the core concepts of the VST service. All the analytics downstream is also related to Sensors.\n",
    "\n",
    "#### Tripwire\n",
    "\n",
    "Tripwire is a construct which is represented as a contigious series of line segments which demarcate a part of the scene across system does counting of crossing. It can easily be thought of as lines marked on the floor of the scene and visualization through a camera live feed.\n",
    "\n",
    "#### Trajectory\n",
    "The actual path a vehicle takes is tracked on a frame by frame basis by the system and recorded. Each vehicle is assigned an ID by the system. The total path for a vehicle is represented by the concept of Trajectory in the system. There is an API to retrieve the trajectory of all the vehicles for a given time range. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configure Tripwire using VST Analytics WebUI\n",
    "\n",
    "The passage of interest will be marked by a Tripwire. For the highway scene we recommend adding a tripwire to represent the lanes i.e South-Bound, North-Bound. \n",
    "\n",
    "To identify the distribution of traffic in case of highway scene, we have a tripwire called South-Bound on the right side of the scene, to analyze vehicles going towards South"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Tripwire configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tripwires](assets/tripwire_config.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Guide\n",
    "\n",
    "Analytics microservices API Guide:\n",
    "\n",
    "https://docs.nvidia.com/moj/emdx_API/index.html\n",
    "\n",
    "Video Storage Toolkit API Guide:\n",
    "\n",
    "https://docs.nvidia.com/moj/vst/VST_API_Guide.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the VST LiveStream Analytics feature, configure 1 tripwire as shown recommended above with the same tripwire names as shown in the image. \n",
    "\n",
    "Open the VST web UI as opened in lab 1. It can be found at `http://{jetson-device-ip}:30080/vst`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Select the Live stream\n",
    "\n",
    "Navigate to Live Streams page from left side navigation panel. \n",
    "From the Live streams section choose the camera of interest from 'Select sensors'\n",
    "\n",
    "To zoom the live stream view. Click on the + zoom icon on the right bottom of the 'Live streams' panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VST_Streams.png](assets/VST_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Open the Analytics panel\n",
    "\n",
    "Click the down arrow to expand the Analytics panel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VST Analytics Panel](assets/VST_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Draw Tripwire points with direction arrow\n",
    "\n",
    "Click on the 'Tripwire' button. \n",
    "Using the left mouse button we will click 4 point on the live stream playing video panel. \n",
    "Create a tripwire similar to what is shown below by marking out the four points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VST_Tripwire_Wire](assets/VST_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now mark the entry direction of the tripwire by clicking the two points such that the second point represents the tip of the arrow direction. See image below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VST_Tripwire_Direction](assets/VST_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be prompted to specify the name of the tripwire. For this particular example specify the name 'South-Bound'. Now click on the 'Done' button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VST_Save](assets/VST_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create remaining tripwires \n",
    "\n",
    "Following the steps 1.1-1.3 create tripwire named South-Bound as shown in the recommended image in introduction section\n",
    "\n",
    "> **Note**: Before continuing, ensure that you have create tripwire in the recommended configuration named \"South-Bound\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vehicle Movement Analytics: Step by Step Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section includes several Python cells that need to be run in this Notebook. Go through and run the cells in order to learn how to use the APIs to build a heatmap of the vehicle traffic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Setup python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python==4.9.0.80 requests==2.31.0 numpy==1.26.4 matplotlib==3.6.2 scipy==1.12.0 shapely==2.0.4 pandas==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from matplotlib import colors\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from urllib import parse\n",
    "\n",
    "from utils import get_tripwire_name_ID_mapping, get_vst_snapshot, plot_pie_chart, plot_stacked_bar_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Configuration \n",
    "\n",
    "#### 2.2.1 Define the API endpoints\n",
    "\n",
    "Make sure the update jetson_device_ip to the IP of your Jetson device below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytics microservice endpoint\n",
    "jetson_device_ip = \"172.17.169.139\" # TODO: change this to the correct device IP\n",
    "endpoint = \"http://{}:30080/emdx\".format(jetson_device_ip)\n",
    "\n",
    "# VST microservice API endpoint\n",
    "vst_endpoint = \"http://{}:30080/vst\".format(jetson_device_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Configure Stream and Sensor\n",
    "\n",
    "In the VST microservice, each camera is represented as a stream. The stream has a unique ID attribute and a user friendly name.  \n",
    "\n",
    "<b><i>Note</i></b>: In the Analytics microservices we have a concept of Sensor which is equivalent to the term Stream in VST microservice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the current sensor information by querying the VST `sensor/list` endpoint as seen below. Additional VST endpoint information can be found in the [MMJ docs](https://docs.nvidia.com/moj/vst/VST_API_Guide.html).\n",
    "\n",
    "Below, run the sample curl command to fetch all sensors currently available in VST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://{jetson_device_ip}:30080/vst/api/v1/sensor/list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one of the `name` values from the JSON returned by the curl command above as the value for sensorId below. This sensor will be used for the rest of this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensorId = \"MOJD2\" # TODO: fill in based on one of the \"name\" values found in the JSON printed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Object Type\n",
    "\n",
    "Object type represent the class of vehicles to be configured for Vehicle Movement Analysis. It is a comma separated list of vehicles type. Each vehicle type in the list should be compliant with YOLOv8 COCO dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectType = \"car,bus,truck\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Get Tripwire Config from API\n",
    "\n",
    "Following method invokes the Analytics API to retrieve all the tripwire configured for a given sensor\n",
    " \n",
    "Note: All Analytics API endpoint expect Sensor Id as specified in the HTTP parameter sensorId.\n",
    "\n",
    "Reference: Tripwire configuration API:\n",
    "\n",
    "https://docs.nvidia.com/moj/emdx/tripwire.html#create-tripwire-configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tripwire_config(endpoint, sensorId):\n",
    "    \"\"\"\n",
    "    Gets the tripwire configurations on a camera sensor\n",
    "\n",
    "    Keyword arguments:\n",
    "    endpoint -- the API endpoint of eMDX\n",
    "    sensorId -- the ID of the camera sensor\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    parameters['sensorId'] = sensorId\n",
    "    encoded_parameters = parse.urlencode(parameters)\n",
    "    url = '{}/api/v2/config/tripwire?{}'.format(endpoint, encoded_parameters)\n",
    "    r = requests.get(url,verify=False)\n",
    "    if r.status_code == 200:\n",
    "        response = r.json()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query this using the cURL command to call analytics microservice `config/tripwire` endpoint to get the current tripwires for a given sensor as seen below. Note the need to specify sensor ID as you set in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://{jetson_device_ip}:30080/emdx/api/v2/config/tripwire?sensorId={sensorId}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Analytics microservice each Tripwire is identified by a unique ID and a user friendly name attribute. Update the tripwireNames array below with the name of the four tripwires you created earlier in section 1. These names should also appear in the JSON above returned by the curl command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the Tripwire names are different than update the 'tripwireNames' list\n",
    "tripwireNames = [\"South-Bound\",\"North-Bound\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the tripwire configurations, we will match specified tripwire names with names of the retrieved tripwire configs to determine id of the each specified tripwire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripwire_config = get_tripwire_config(endpoint, sensorId)\n",
    "tripwireIdMap, tripwireNameMap = get_tripwire_name_ID_mapping(tripwire_config, tripwireNames)\n",
    "tripwireIds = list(tripwireIdMap.keys())\n",
    "tripwireId = tripwireIds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toTimestamp is the current time while fromTimestamp is the timestamp 5 minutes ago. Change these values as desired.\n",
    "toTimestamp = datetime.utcnow()\n",
    "fromTimestamp = toTimestamp - timedelta(minutes=5)\n",
    "\n",
    "toTimestamp = toTimestamp.isoformat(\"T\")[0:-3] + \"Z\"\n",
    "fromTimestamp = fromTimestamp.isoformat(\"T\")[0:-3] + \"Z\"\n",
    "\n",
    "# Timerange for which analytics needs to be fetched, in iso8601 formats in milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the duration b/w toTimestamp and fromTimestamp is divided into fixed size windows\n",
    "# update the desired size in seconds\n",
    "windowSize = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Vehicle Movement Analytics \n",
    "\n",
    "#### 2.3.1 Retrieve the Tripwire entry / exits histogram for a given time range from API\n",
    "\n",
    "This function calls Tripwire Analytics Histogram API to get entry and exit counts for a given timerange and bucketed into fixed intervals of given size i.e. windowSize.\n",
    "\n",
    "Reference: Tripwire Histogram API\n",
    "\n",
    "https://docs.nvidia.com/moj/emdx/tripwire.html#retrieve-tripwire-counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query this curl command to call the Analytics microservice `/metrics/tripwire/histogram` endpoint to get the histogram counts for a tripwire for a given sensor, timerange and window size as seen below. Note the need to specify sensor ID, tripwire ID, fromTimestamp, toTimestamp, objectType and bucketSizeInSec in the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \"http://{jetson_device_ip}:30080/emdx/api/v2/metrics/tripwire/histogram?fromTimestamp={fromTimestamp}&toTimestamp={toTimestamp}&sensorId={sensorId}&tripwireId={tripwireId}&objectType={objectType}&bucketSizeInSec={windowSize}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tripwire_histogram_by_direction(endpoint, sensorId, fromTimestamp, toTimestamp, tripwireId, objectType=\"car,bus,truck\", windowSize=5):\n",
    "    \"\"\"\n",
    "    Gets the tripwire histogram and time ranges for a tripwire using API for crossing from each direction for each window of given size\n",
    "\n",
    "    Keyword arguments:\n",
    "    endpoint -- the API endpoint of eMDX\n",
    "    sensorId -- the ID of the camera sensor\n",
    "    fromTimestamp -- start time for the required data timerange in iso8601 format in milliseconds\n",
    "    toTimestamp -- end time for the required data timerange in iso8601 format in milliseconds\n",
    "    tripwireId -- the ID of the tripwire\n",
    "    windowSize -- the entire duration is divided into windows of given window_size in milliseconds\n",
    "    objectType -- comma separated list of object classes e.g. car,bus,truck\n",
    "\n",
    "    Returns a dictionary in the following format:\n",
    "    {`tripwireId-1`: {\"entry\": `crossing counts`, \"exit\": `crossing counts`}, `tripwireId-2`:...}\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    parameters['sensorId'] = sensorId\n",
    "    parameters['bucketSizeInSec'] = windowSize\n",
    "    # This is the histogram bin size\n",
    "    parameters['toTimestamp'] = toTimestamp\n",
    "    parameters['fromTimestamp'] = fromTimestamp\n",
    "    parameters['objectType'] = objectType\n",
    "    # histogram counts and returned in this timerange\n",
    "\n",
    "    parameters['tripwireId'] = tripwireId\n",
    "    encoded_parameters = parse.urlencode(parameters)\n",
    "    # this API gets histograms of tripwire count in each direction for the given timerange\n",
    "    url = '{}/api/v2/metrics/tripwire/histogram?{}'.format(endpoint, encoded_parameters)\n",
    "    #print(f\"url : {url}\")\n",
    "    r = requests.get(url,verify=False)\n",
    "    if r.status_code == 200:\n",
    "        response = r.json()\n",
    "    \n",
    "    time_range = []\n",
    "    object_counts = {}\n",
    "    if response:\n",
    "        tripwires = response['tripwires']\n",
    "        for tripwire in tripwires:\n",
    "            if tripwire[\"id\"] == tripwireId:\n",
    "                histograms = tripwire[\"histogram\"]\n",
    "                for record in histograms:\n",
    "                    start = record[\"start\"]\n",
    "                    end = record[\"end\"]\n",
    "                    time_range.append(f\"{start[:-5]} - {end[:-5]}\")\n",
    "                    events = record[\"events\"]\n",
    "                    for event in events:\n",
    "                        direction = event[\"type\"]\n",
    "                        #print(f\"direction : {direction}, object_counts: {object_counts}\")\n",
    "                        if direction not in object_counts:\n",
    "                            object_counts[direction] = {}\n",
    "                        objects = event[\"objects\"]\n",
    "                        for obj in objects:\n",
    "                            obj_type = obj[\"type\"]\n",
    "                            if obj_type!=\"*\":\n",
    "                                if obj_type not in object_counts[direction]:\n",
    "                                    object_counts[direction][obj_type] = []\n",
    "                                object_counts[direction][obj_type].append(obj[\"count\"])\n",
    "                break\n",
    "    \n",
    "    return object_counts, time_range\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Visualize vehicle traffic trends using Stacked bar chart\n",
    "\n",
    "What is a Stacked Bar Chart?\n",
    "The stacked bar chart (aka stacked bar graph) extends the standard bar chart from looking at numeric values across one categorical variable to multiple.\n",
    "\n",
    "This chart represents the vehicle count within a specified timerange (as specified by fromTimestamp/toTimstamp parameters) for each direction. The timerange is divided into fixed windows (as specified by windowSize parameter). Within each time window, the chart uses color-coded bars to denote the count of each vehicle type i.e. car, bus, truck.\n",
    "The height of each color within a bar directly corresponds to vehicle count for that category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a stacked bar chart:\n",
    "\n",
    "First, we will define a function that invokes the histogram endpoint.\n",
    "This function returns the counts of each objects in the scene for each window within the given time slot and also the time ranges for each window and all direction i.e. entry,exit\n",
    "We then use these outputs to plot a separate stacked bar chart for each direction.\n",
    "\n",
    "Note: Graph is only plotted if there in any non-zero count for any object for a particular direction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, tripwireId in enumerate(tripwireIds):\n",
    "    object_histogram_by_direction, time_range_list = get_tripwire_histogram_by_direction(endpoint, sensorId, fromTimestamp, toTimestamp, tripwireId, objectType, windowSize)\n",
    "\n",
    "    # plot the histogram for each direction\n",
    "    for direction in object_histogram_by_direction:\n",
    "        tripwireName = tripwireIdMap[tripwireId]\n",
    "        print(\"==========================================================\")\n",
    "        print(f\"**Histogram for tripwire - {tripwireName} , direction={direction}**\")\n",
    "        print(\"==========================================================\")\n",
    "        if object_histogram_by_direction[direction] != {}:\n",
    "            plot_stacked_bar_chart(time_range_list, object_histogram_by_direction[direction], fromTimestamp, toTimestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Retrieve the Tripwire entry / exits counts for a given time range from API\n",
    "This function calls Tripwire Analytics Count API to get entry and exit counts for a given timerange for given object types\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query this curl command to call the Analytics microservice /metrics/tripwire endpoint to get the counts for a tripwire for a given sensor, timerange for all directions as seen below. Note the need to specify sensor ID, tripwire ID, fromTimestamp, toTimestamp, objectType in the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \"http://{jetson_device_ip}:30080/emdx/api/v2/metrics/tripwire?fromTimestamp={fromTimestamp}&toTimestamp={toTimestamp}&sensorId={sensorId}&tripwireId={tripwireId}&objectType={objectType}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tripwire_counts_by_direction(endpoint, sensorId, fromTimestamp, toTimestamp, tripwireId, objectType=\"car,bus,truck\"):\n",
    "    \"\"\"\n",
    "    Gets the tripwire crossing counts for a tripwire using API for crossing from each direction\n",
    "\n",
    "    Keyword arguments:\n",
    "    endpoint -- the API endpoint of eMDX\n",
    "    sensorId -- the ID of the camera sensor\n",
    "    fromTimestamp -- start time for the required data timerange in iso8601 format in milliseconds\n",
    "    toTimestamp -- end time for the required data timerange in iso8601 format in milliseconds\n",
    "    tripwireId -- the ID of the tripwire\n",
    "    objectType -- comma separated list of object classes e.g. car,bus,truck\n",
    "\n",
    "    Returns a dictionary in the following format:\n",
    "    {`tripwireId-1`: {\"entry\": `crossing counts`, \"exit\": `crossing counts`}, `tripwireId-2`:...}\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    parameters['sensorId'] = sensorId\n",
    "    # This is the histogram bin size\n",
    "    parameters['toTimestamp'] = toTimestamp\n",
    "    parameters['fromTimestamp'] = fromTimestamp\n",
    "    parameters['objectType'] = objectType\n",
    "    parameters['tripwireId'] = tripwireId\n",
    "\n",
    "\n",
    "    # counts w.r.t each object type in this timerange for each direction\n",
    "\n",
    "    total_object_counts = {}\n",
    "    encoded_parameters = parse.urlencode(parameters)\n",
    "    # this API gets histograms of tripwire count in each direction for the given timerange\n",
    "    url = '{}/api/v2/metrics/tripwire?{}'.format(endpoint, encoded_parameters)\n",
    "    r = requests.get(url,verify=False)\n",
    "    if r.status_code == 200:\n",
    "        response = r.json()\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    if response:\n",
    "        tripwirekpis = response[\"tripwireKpis\"]\n",
    "        for tripwirekpi in tripwirekpis:\n",
    "            if tripwirekpi[\"id\"] == tripwireId:\n",
    "                events = tripwirekpi[\"events\"]\n",
    "                for event in events:\n",
    "                    direction = event[\"type\"]\n",
    "                    if direction not in result_dict:\n",
    "                        result_dict[direction] = {}\n",
    "                    objects = event[\"objects\"]\n",
    "                    for obj in objects:\n",
    "                        obj_type = obj[\"type\"]\n",
    "                        if obj_type !=\"*\":\n",
    "                            result_dict[direction][obj_type] = obj[\"count\"]\n",
    "                break\n",
    "        \n",
    "\n",
    "    return result_dict\n",
    "\n",
    "get_tripwire_counts_by_direction(endpoint, sensorId, fromTimestamp, toTimestamp, tripwireIds[0], objectType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tripwire_results = {}\n",
    "for tripwireId in tripwireIds:\n",
    "    all_tripwire_results[tripwireId] = get_tripwire_counts_by_direction(endpoint, sensorId, fromTimestamp, toTimestamp, tripwireId, objectType)\n",
    "all_tripwire_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Get Image snapshot of the live stream using VST API\n",
    "\n",
    "We will now retrieve the image snapshot of the live stream from VST. This is required to visualize the traffic distribution across groups and visualize it on the scene image snapshot.\n",
    "\n",
    "- Retrieve the stream ID of the specified stream by name using method get_stream_id_from_sensor_id\n",
    "- Retrieve the image snapshot for a given stream ID by using method get_snapshot_data\n",
    "- Store it as an OpenCV image object\n",
    "\n",
    "Reference: VST API Guide\n",
    "\n",
    "https://docs.nvidia.com/moj/vst_API/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_id_from_sensor_id(vst_endpoint, sensorId):\n",
    "  \"\"\"\n",
    "  Gets the stream ID of the camera sensor from VST API\n",
    "\n",
    "  Keyword arguments:\n",
    "  vst_endpoint -- the API endpoint of VST\n",
    "  sensorId -- the ID of the camera sensor\n",
    "\n",
    "  Return Value:\n",
    "  streamID -- stream ID of the camera sensor\n",
    "  \"\"\"\n",
    "  # API to get all the live camera streams\n",
    "  url = '{}/api/v1/live/streams'.format(vst_endpoint)\n",
    "  r = requests.get(url,verify=False)\n",
    "  if r.status_code == 200:\n",
    "    all_streams_response = r.json()\n",
    "    for streams_data in all_streams_response:\n",
    "      for _, streams_list in streams_data.items():\n",
    "        for stream in streams_list:\n",
    "          if stream[\"name\"] == sensorId:\n",
    "            return stream[\"streamId\"]\n",
    "          \n",
    "def get_snapshot_data(vst_endpoint, streamId):\n",
    "  \"\"\"\n",
    "  Gets the snapshot data of the camera sensor from VST API\n",
    "\n",
    "  Keyword arguments:\n",
    "  vst_endpoint -- the API endpoint of VST\n",
    "  streamId -- the stream ID of the camera sensor\n",
    "\n",
    "  Returns API response with image content in bytes\n",
    "  \"\"\"\n",
    "  # API to get sensor snapshot\n",
    "  url = '{}/api/v1/live/stream/{}/picture'.format(vst_endpoint, streamId)\n",
    "  r = requests.get(url,verify=False)\n",
    "  if r.status_code == 200:\n",
    "    return r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query this curl command to call the VST microservice `v1/live/streams` endpoint to get all the current live streams. This contains the streamId necessary to make the call to fetch snapshot data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://{jetson_device_ip}:30080/vst/api/v1/live/streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query this cURL command to call VST microservice `/v1/live/stream/{streamId}/picture` endpoint to get the snapshot of the stream with a streamID. Note the need to specify stream ID which can be fetched from the `/v1/live/streams` endpoint.\n",
    "\n",
    "`curl http://{jetson_device_ip}:30080/vst/api/v1/live/stream/{vst_streamId}/picture`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Visualize Tripwire Group Counts on the scene image snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_tripwire_analytics(cv2_image, tripwire_config, tripwire_map, tripwire_count_results, tripwire_color):\n",
    "    \"\"\"\n",
    "    Plots all the tripwire analytics results on the image. It also tells the distribution percentage of counts between different tripwires\n",
    "\n",
    "    Keyword arguments:\n",
    "    cv2_image -- an opencv image object which is a snapshot of the camera sensor scene\n",
    "    tripwire_config -- tripwire config response returned by the eMDX API endpoint\n",
    "    tripwire_map -- the dictionary that maps tripwire ID to tripwire name\n",
    "    tripwire_count_results -- dictionary which contains tripwire counts for which this function will overlay the analytics\n",
    "    tripwire_color -- color of the tripwire to be overlayed on the image\n",
    "    \"\"\"  \n",
    "    tripwires = tripwire_config['tripwires']\n",
    "    height, width = cv2_image.shape[:2]\n",
    "    arrow_head = (width//2, height//2)\n",
    "\n",
    "    total_crossings = 0\n",
    "    \n",
    "    for tripwire in tripwires:\n",
    "        analytics_overlay_details = []\n",
    "        tripwireId = tripwire['id']\n",
    "        if tripwireId in tripwire_count_results:\n",
    "            coordinates = np.array([(point['x'], point['y']) for point in tripwire['wire']])\n",
    "            # draws the tripwire\n",
    "            cv2.polylines(cv2_image, [coordinates.astype(int)], isClosed=False, color=tripwire_color, thickness=2)\n",
    "            # writes the tripwire name\n",
    "            cv2.putText(cv2_image, str(tripwire_map[tripwire['id']]),\\\n",
    "                     (int(coordinates[0][0] + 5), int(coordinates[0][1] - 5)), cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=tripwire_color, thickness=2)\n",
    "            crossing_directions = list(tripwire_count_results[tripwireId].keys())\n",
    "            text_pos = (coordinates[1] + coordinates[2])//2\n",
    "            \n",
    "            for direction in crossing_directions:\n",
    "                if any(tripwire_count_results[tripwireId][direction].values()):\n",
    "                    analytics_overlay_details.append({\"text_pos\": text_pos, \"obj_count\": tripwire_count_results[tripwireId][direction], \"direction\": direction})\n",
    "                    total_crossings+=sum(tripwire_count_results[tripwireId][direction].values())\n",
    "    \n",
    "            text_pos = (coordinates[0][0]+ 20, coordinates[0][1]+ 35)\n",
    "            for analytics in analytics_overlay_details:\n",
    "                #text_pos = (int(analytics[\"text_pos\"][0]), int(analytics[\"text_pos\"][1] - 20))\n",
    "                text = f\"{analytics['direction']}: \" \n",
    "                text += ', '.join([f\"{key}={value}\" for key,value in analytics[\"obj_count\"].items()])\n",
    "                # overlays the counts of each object for each direction\n",
    "                cv2.putText(cv2_image, text,\\\n",
    "                            text_pos, cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=tripwire_color, thickness=2)\n",
    "                text_pos = (text_pos[0], text_pos[1]+ 40)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return cv2_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize the above function to create an overlay for all the tripwire crossing analytics. The number shown next to each tripwire specifies the number of crossings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamId = get_stream_id_from_sensor_id(vst_endpoint, sensorId)\n",
    "img_content = get_snapshot_data(vst_endpoint, streamId)\n",
    "cv2_image = get_vst_snapshot(img_content)\n",
    "# First overly the group-1 statistic \n",
    "img = overlay_tripwire_analytics(cv2_image, tripwire_config, tripwireIdMap, all_tripwire_results, (255, 255, 0))\n",
    "\n",
    "# Save the image\n",
    "cv2.imwrite(\"tripwire-viz.jpg\", img)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Heatmap based Traffic Movement Analytics\n",
    "### What is a heatmap ?\n",
    "A heatmap is a visual representation of time spent by an object in a particular location. In this section of the notebook, we analyze vehicle trajectories using heatmaps.\n",
    "\n",
    "Firstly the trajectories captured from a sensor are obtained for a given time window. Further, the trajectories are then classified based on the tripwires they cross. Then, a 2D histogram of required size is computed for points in all the trajectories of a class. The 2D histogram is further smoothened to obtain the final heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a heatmap:\n",
    "* First, we will define a function that invokes the behavior endpoint\n",
    "  * This function returns the behaviours of all the objects in the scene within the given time slot\n",
    "* We then convert the response from behavior endpoint, into trajectories based on their object ID\n",
    "* Then we define a set of functions that are needed to classify the trajectories using the tripwires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get object trajectories within a given time window\n",
    "Trajectory is a list of (x, y) coordinates of mid point of lower edge of the detected object bounding boxes.\n",
    "In order to build a heatmap , we use these points in the Trajectory.\n",
    "\n",
    "\n",
    "#### 3.1.1 Retrieve behaviors from API\n",
    "\n",
    "We can use `/emdx/api/v2/behavior` endpoint to get the list of all object trajectory points sorted by their timestamp within a given time window.\n",
    "Each entry in the response of the endpoint includes the following:\n",
    "* timestamp\n",
    "* Object ID\n",
    "* X, Y coordinates of the trajectory point of the object\n",
    "\n",
    "The `get_behaviors` method below invokes the endpoint with sensorId, time window specified by their to and from timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behaviors(endpoint, sensorId, fromTimestamp, toTimestamp, objectType):\n",
    "    \"\"\"\n",
    "    This method calls the /emdx/api/v2/behavior endpoint\n",
    "    \n",
    "    Keyword arguments:\n",
    "    sensorId -- ID of the sensor as per the config\n",
    "    fromTimestamp -- a datetime object representing the start of time window\n",
    "    toTimestamp -- a datetime object representing the end of time window\n",
    "    \"\"\"\n",
    "    fromTimestamp = fromTimestamp.isoformat(timespec='milliseconds').replace('+00:00', 'Z')\n",
    "    toTimestamp = toTimestamp.isoformat(timespec='milliseconds').replace('+00:00', 'Z')\n",
    "    objectType = objectType\n",
    "    \n",
    "    parameters = {}\n",
    "    parameters['sensorId'] = sensorId\n",
    "    # This is the histogram bin size\n",
    "    parameters['toTimestamp'] = toTimestamp\n",
    "    parameters['fromTimestamp'] = fromTimestamp\n",
    "    parameters['objectType'] = objectType\n",
    "    # histogram counts and returned in this timerange\n",
    "\n",
    "    encoded_parameters = parse.urlencode(parameters)\n",
    "    # this API gets histograms of tripwire count in each direction for the given timerange\n",
    "    url = '{}/api/v2/behavior?{}'.format(endpoint, encoded_parameters)\n",
    "    \n",
    "    #url = f\"{endpoint}/api/v2/behavior?sensorId={sensorId}&fromTimestamp={fromTimestamp}&toTimestamp={toTimestamp}&objectType={objectType}\"\n",
    "\n",
    "    payload = \"\"\n",
    "    headers = {}\n",
    "    behaviors = []\n",
    "    try:\n",
    "        r = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "        if r.status_code == 200:\n",
    "            response = r.json()\n",
    "            #response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "            behaviors = response['behaviors']\n",
    "    except:\n",
    "        print(f\"Error in getting trajectories for sensor {sensorId} from {fromTimestamp} to {toTimestamp}\")\n",
    "        print(url)\n",
    "        print(response.text)\n",
    "    \n",
    "    return behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Extract trajectories from behaviors\n",
    "\n",
    "The maximum allowed time window for the `/behavior` endpoint is 5 seconds. Therefore, it needs to be called multiple times in order to obtain the behaviors for time window larger than the specified limit.\n",
    "\n",
    "Therefore, the `get_trajectories` method given below aggregates the object behaviors for each 5 second interval.\n",
    "It then creates and returns a list of dataframes, where each dataframe contains the (timestamp, x coordinate, y coordinate) per object ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectories(endpoint, sensorId, fromTimestamp, toTimestamp, objectType):\n",
    "    \"\"\"\n",
    "    This method splits the input time window into 5 second intervals.\n",
    "    On each 5 second interval, it calls the get_behaviors method\n",
    "    It accumulates and returns all the trajectories collected from each interval\n",
    "    \"\"\"\n",
    "    print(f\"Getting trajectories for sensor {sensorId} from: {fromTimestamp}, to: {toTimestamp}\")\n",
    "    trajs = []\n",
    "    objects = {}\n",
    "    \n",
    "    while fromTimestamp < toTimestamp:\n",
    "        delta_in_secs = (toTimestamp - fromTimestamp).seconds\n",
    "        min_delta_in_secs = min(5, delta_in_secs)\n",
    "        \n",
    "        start_time = fromTimestamp\n",
    "        end_time = fromTimestamp + timedelta(seconds=min_delta_in_secs)\n",
    "        \n",
    "        fromTimestamp = end_time\n",
    "        behaviors = get_behaviors(endpoint, sensorId, start_time, end_time, objectType)\n",
    "\n",
    "        for behavior in behaviors:\n",
    "            obj_id = behavior[\"object\"][\"id\"]\n",
    "            obj_type = behavior[\"object\"][\"type\"]\n",
    "            obj_coords = behavior['locations']['coordinates']\n",
    "\n",
    "            points = [\n",
    "                [t, x, y]\n",
    "                for t, [x, y] in obj_coords\n",
    "            ]\n",
    "\n",
    "            obj_points = objects.get(obj_id, [])\n",
    "            obj_points += points\n",
    "            objects[obj_id] = obj_points\n",
    "    \n",
    "    for points in objects.values():\n",
    "        df = pd.DataFrame(points)\n",
    "        df.columns = ['ts', 'x', 'y']\n",
    "\n",
    "        trajs.append(df)\n",
    "\n",
    "    print(f\"Got {len(trajs)} trajectories\")\n",
    "    \n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below, invokes the `get_trajectories` method for a time window that lasts 1 minute from the current time (as defined by `time_delta_in_mins` variable). This may take a few seconds to run.\n",
    "\n",
    "*However, to account for the latency in computing the behaviors and to allow for any detections to happen within the given time window, we offset the current timestamp by 5 minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentTimestamp = datetime.now(timezone.utc) - timedelta(minutes=5)\n",
    "time_delta_in_mins = 1\n",
    "\n",
    "fromTimestamp = currentTimestamp - timedelta(minutes=time_delta_in_mins)\n",
    "toTimestamp = currentTimestamp\n",
    "\n",
    "trajs = get_trajectories(endpoint, sensorId, fromTimestamp, toTimestamp, objectType)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to computing and plotting the heatmap, we grab an image frame from the video stream of sensor using VST endpoint.\n",
    "\n",
    "We use this image frame to determine the dimensions of the heatmap as well as to use it as the background for overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the latest camera frame from the sensor using VST endpoint\n",
    "streamId = get_stream_id_from_sensor_id(vst_endpoint, sensorId)\n",
    "img_content = get_snapshot_data(vst_endpoint, streamId)\n",
    "image = get_vst_snapshot(img_content)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img_width, img_height = image.shape[1], image.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Generate Heatmap of Vehicle Movement\n",
    "\n",
    "This section defines the functions to compute and plot the heatmap of a list of trajectories\n",
    "\n",
    "Try different values for scale and smoothness of the generated heatmap\n",
    "* scale - controls the resolution of output heatmap (preferred values are from 2 to 10)\n",
    "  * higher value of scale, results in lower resolution of heatmap\n",
    "* smoothness - controls the variance of smoothening (gaussian) filter (preferred values are from 2 to 10)\n",
    "  * higher value of smoothness creates highly smoothened heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_heatmap\n",
    "H = plot_heatmap(trajs, image, name='Heatmap of all trajectories')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
