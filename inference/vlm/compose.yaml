# SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

services:
  jps_vlm:
    image: nvcr.io/nvidia/jps/vlm_infer:2.0.0
    user: "2009:150"
    network_mode: "host"
    runtime: nvidia
    logging:
      driver: "json-file"
      options:
        max-size: "8192m"
        max-file: "3"
    environment:
      MAIN_CONFIG_PATH: /config/main_config.json
      CHAT_SERVER_CONFIG_PATH: /config/chat_server_config.json
      TRANSFORMERS_CACHE: /data/models/huggingface

    restart: always
    container_name: jps_vlm
    volumes:
      - /tmp/argus_socket:/tmp/argus_socket
      - /etc/enctune.conf:/etc/enctune.conf
      - /etc/nv_tegra_release:/etc/nv_tegra_release
      - /data/genai-volume:/data
      - /data/logging-volume:/data/logging-volume
      - ./config:/config
      - type: bind
        source: /proc/device-tree/model
        target: /tmp/nv_jetson_model
        read_only: True

    command: bash -c "/jetson-services/inference/vlm/docker_start.sh | tee -a /data/logging-volume/vlm.log"
    
    deploy:
      restart_policy:
        condition: always